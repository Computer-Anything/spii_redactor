{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ba2009",
   "metadata": {},
   "source": [
    "# PII DETECTION AND REDACTION\n",
    "\n",
    "In this notebook, we will be using the `pii` library to detect and redact PII (Personally Identifiable Information) from text.\n",
    "\n",
    "## Step 1: Install and import the required and necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a77a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "%pip install easyocr spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32193d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import easyocr\n",
    "import spacy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fb71b",
   "metadata": {},
   "source": [
    "## Step 2: Check and toggle the GPU or CPU for computation speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to toggle between CPU and GPU\n",
    "def get_device(use_gpu=True):\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Default to GPU\n",
    "device = get_device(use_gpu=True)\n",
    "\n",
    "# Example: Moving a tensor to the selected device\n",
    "x = torch.randn(3, 3).to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2c172",
   "metadata": {},
   "source": [
    "## Step 3: Initialize EasyOCR and SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107bd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EasyOCR and SpaCy\n",
    "reader = easyocr.Reader(['en'], gpu=True)  # OCR with GPU support\n",
    "nlp = spacy.load('en_core_web_sm')        # SpaCy NLP model for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a710b32",
   "metadata": {},
   "source": [
    "## Step 4: Write a function to OCR an image and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da5f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform OCR and extract text\n",
    "def extract_text(image_path, reader):\n",
    "    results = reader.readtext(image_path, detail=0)  # Extract text without bounding box details\n",
    "    return \" \".join(results)  # Combine all extracted text into a single string\n",
    "\n",
    "# Example usage\n",
    "image_path = \"image path\"  # Replace with your image path\n",
    "extracted_text = extract_text(image_path, reader)\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8428a0",
   "metadata": {},
   "source": [
    "## Step 5: Write a function to detect and redact PII entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a60217b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to detect and redact PII entities using SpaCy and regex\n",
    "def redact_pii(text):\n",
    "    \"\"\"\n",
    "    Detect and redact PII (emails, phone numbers, zip codes, etc.) from the text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to process.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with PII redacted.\n",
    "    \"\"\"\n",
    "    # Process the text with SpaCy\n",
    "    doc = nlp(text)\n",
    "    redacted_text = text\n",
    "\n",
    "    # Redact specific entities detected by SpaCy\n",
    "    for ent in doc.ents:\n",
    "        print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n",
    "        if ent.label_ in ['PERSON']:  # Only redact PERSON entities\n",
    "            redacted_text = re.sub(r'\\b' + re.escape(ent.text) + r'\\b', '[REDACTED]', redacted_text)\n",
    "\n",
    "    # Custom regex patterns for emails, phone numbers, and zip codes\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+\\s*@\\s*[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    phone_pattern = r'\\b(?:\\+?1[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
    "    zip_code_pattern = r'\\b\\d{5}(?:-\\d{4})?\\b'\n",
    "\n",
    "    # Redact emails\n",
    "    redacted_text = re.sub(email_pattern, '[REDACTED EMAIL]', redacted_text)\n",
    "    # Redact phone numbers\n",
    "    redacted_text = re.sub(phone_pattern, '[REDACTED PHONE]', redacted_text)\n",
    "    # Redact zip codes\n",
    "    redacted_text = re.sub(zip_code_pattern, '[REDACTED ZIP]', redacted_text)\n",
    "\n",
    "    return redacted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62f452",
   "metadata": {},
   "source": [
    "## Step 6: Put it together and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f7aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the original image and redacted text side by side\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_results(image, redacted_text):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Display the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Original Image\")\n",
    "\n",
    "    # Display the redacted text\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.text(0.5, 0.5, redacted_text, fontsize=12, wrap=True, ha=\"center\", va=\"center\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Redacted Text\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Final function to process the image and display results\n",
    "def process_image(image_path, reader):\n",
    "    # Step 1: Extract text using EasyOCR\n",
    "    extracted_text = extract_text(image_path, reader)\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "\n",
    "    # Step 2: Redact PII from the extracted text\n",
    "    redacted_text = redact_pii(extracted_text)\n",
    "    print(\"\\nRedacted Text:\")\n",
    "    print(redacted_text)\n",
    "\n",
    "    # Step 3: Display the original image and redacted text side by side\n",
    "    image = Image.open(image_path)\n",
    "    display_results(image, redacted_text)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"image_path\"  # Replace with your image path\n",
    "process_image(image_path, reader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
