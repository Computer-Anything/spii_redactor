{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a074e8e6",
   "metadata": {},
   "source": [
    "1. Imports and Setup:\n",
    "\n",
    "Place all imports (e.g., torch, transformers, etc.) and environment setup (e.g., GPU configuration) at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f19025fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Verify tensor placement\n",
    "x = torch.randn(3, 3).to(device)\n",
    "print(\"Tensor is on device:\", x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881427dc",
   "metadata": {},
   "source": [
    "2. Define the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f16fa8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "label_to_id = {\"O\": 0, \"PERSON\": 1, \"ORG\": 2, \"PHONE\": 3, \"EMAIL\": 4}  # Example label mapping\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_to_id))\n",
    "model.to(device)\n",
    "\n",
    "# Verify model placement\n",
    "print(\"Model is on device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d86236",
   "metadata": {},
   "source": [
    "3. Load Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bba0c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 24\n"
     ]
    }
   ],
   "source": [
    "from training_data import TRAIN_DATA\n",
    "\n",
    "# Print the number of training examples\n",
    "print(\"Number of training examples:\", len(TRAIN_DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157a10a",
   "metadata": {},
   "source": [
    "4. Preprocess Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dd2b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenizer (using a pre-trained tokenizer, e.g., BERT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, val_data = train_test_split(TRAIN_DATA, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocess_data function\n",
    "def preprocess_data(data, tokenizer, label_to_id):\n",
    "    tokenized_data = []\n",
    "\n",
    "    for text, annotations in data:\n",
    "        # Tokenize the text\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",  # Pad to the maximum length\n",
    "            truncation=True,       # Truncate if the text is too long\n",
    "            max_length=128,        # Maximum sequence length\n",
    "            return_offsets_mapping=True,  # Get character offsets\n",
    "            return_tensors=\"pt\"    # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Initialize labels with \"O\" (outside any entity)\n",
    "        labels = [label_to_id[\"O\"]] * len(tokenized[\"input_ids\"][0])\n",
    "\n",
    "        # Align labels with tokens\n",
    "        offsets = tokenized[\"offset_mapping\"][0].tolist()\n",
    "        for start, end, label in annotations[\"entities\"]:\n",
    "            for idx, (token_start, token_end) in enumerate(offsets):\n",
    "                if token_start >= start and token_end <= end:\n",
    "                    labels[idx] = label_to_id[label]\n",
    "\n",
    "        # Remove offset mapping (not needed for training)\n",
    "        tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "        # Add labels to the tokenized data\n",
    "        tokenized[\"labels\"] = torch.tensor(labels)\n",
    "\n",
    "        tokenized_data.append(tokenized)\n",
    "\n",
    "    return tokenized_data\n",
    "\n",
    "# Preprocess training and validation data\n",
    "tokenized_train_data = preprocess_data(train_data, tokenizer, label_to_id)\n",
    "tokenized_val_data = preprocess_data(val_data, tokenizer, label_to_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc11a442",
   "metadata": {},
   "source": [
    "5. Create DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06030ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val.clone().detach() for key, val in self.data[idx].items()}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item['input_ids'].squeeze(0) for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'].squeeze(0) for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "# Create DataLoaders with the custom collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ee5a2",
   "metadata": {},
   "source": [
    "6. Train the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b28065f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1, Loss: 0.03443974629044533\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 2, Step 1, Loss: 0.03235198184847832\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 3, Step 1, Loss: 0.030262792482972145\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 4, Step 1, Loss: 0.02982369065284729\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 5, Step 1, Loss: 0.028297170996665955\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 6, Step 1, Loss: 0.02617095224559307\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 7, Step 1, Loss: 0.024763695895671844\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 8, Step 1, Loss: 0.02251618355512619\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 9, Step 1, Loss: 0.021297059953212738\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 10, Step 1, Loss: 0.020143218338489532\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 11, Step 1, Loss: 0.018370909616351128\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 12, Step 1, Loss: 0.017452724277973175\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 13, Step 1, Loss: 0.016586655750870705\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 14, Step 1, Loss: 0.014748582616448402\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 15, Step 1, Loss: 0.014908231794834137\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 16, Step 1, Loss: 0.013187740929424763\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 17, Step 1, Loss: 0.013744322583079338\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 18, Step 1, Loss: 0.012551656924188137\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 19, Step 1, Loss: 0.01097515132278204\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 20, Step 1, Loss: 0.009634716436266899\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 21, Step 1, Loss: 0.009164392948150635\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 22, Step 1, Loss: 0.009405379183590412\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 23, Step 1, Loss: 0.00815916620194912\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 24, Step 1, Loss: 0.008274928666651249\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 25, Step 1, Loss: 0.007119542919099331\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 26, Step 1, Loss: 0.006824938580393791\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 27, Step 1, Loss: 0.00638109864667058\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 28, Step 1, Loss: 0.005882670637220144\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 29, Step 1, Loss: 0.005666252225637436\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 30, Step 1, Loss: 0.005293961614370346\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 31, Step 1, Loss: 0.0046308995224535465\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 32, Step 1, Loss: 0.00441959360614419\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 33, Step 1, Loss: 0.003937241621315479\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 34, Step 1, Loss: 0.0035579465329647064\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 35, Step 1, Loss: 0.0033478951081633568\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 36, Step 1, Loss: 0.0034745109733194113\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 37, Step 1, Loss: 0.0033772599417716265\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 38, Step 1, Loss: 0.0030900840647518635\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 39, Step 1, Loss: 0.0028813760727643967\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 40, Step 1, Loss: 0.003340478055179119\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 41, Step 1, Loss: 0.0023221697192639112\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 42, Step 1, Loss: 0.0024340508971363306\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 43, Step 1, Loss: 0.0026366328820586205\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 44, Step 1, Loss: 0.002104029059410095\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 45, Step 1, Loss: 0.0020734965801239014\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 46, Step 1, Loss: 0.0020535963121801615\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 47, Step 1, Loss: 0.0018147336086258292\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 48, Step 1, Loss: 0.0016675967490300536\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 49, Step 1, Loss: 0.0017696882132440805\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Epoch 50, Step 1, Loss: 0.0019417456351220608\n",
      "Allocated memory: 2516.46 MB\n",
      "Reserved memory: 4106.00 MB\n",
      "Validation Loss: 0.12255516648292542\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Gradient accumulation steps\n",
    "accumulation_steps = 4  # Simulate a larger batch size by accumulating gradients\n",
    "\n",
    "# Training loop with gradient accumulation\n",
    "for epoch in range(50):  # Train for 20 epochs instead of 10\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / accumulation_steps  # Scale loss by accumulation steps\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights after accumulating gradients\n",
    "        if (step + 1) % accumulation_steps == 0 or (step + 1) == len(train_loader):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Step {step + 1}, Loss: {loss.item()}\")\n",
    "        print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"Reserved memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "for batch in val_loader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        val_loss += outputs.loss.item()\n",
    "\n",
    "val_loss /= len(val_loader)\n",
    "print(f\"Validation Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e4d5a",
   "metadata": {},
   "source": [
    "7. Save the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "292afe0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'ner_model'\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model with label mappings\n",
    "model.config.id2label = {v: k for k, v in label_to_id.items()}  # Map IDs to labels\n",
    "model.config.label2id = label_to_id  # Map labels to IDs\n",
    "\n",
    "model.save_pretrained(\"ner_model\")\n",
    "tokenizer.save_pretrained(\"ner_model\")\n",
    "print(\"Model saved to 'ner_model'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a7823",
   "metadata": {},
   "source": [
    "8. Test the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63a60c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: John Doe works at Acme Corp. His email is john.doe@acme.com and phone is 123-456-7890.\n",
      "Entities: [{'entity': 'PERSON', 'score': np.float32(0.44597924), 'index': 1, 'word': 'john', 'start': 0, 'end': 4}, {'entity': 'PERSON', 'score': np.float32(0.37545097), 'index': 2, 'word': 'doe', 'start': 5, 'end': 8}, {'entity': 'EMAIL', 'score': np.float32(0.7598781), 'index': 13, 'word': '.doe@acme.com', 'start': 46, 'end': 59}, {'entity': 'PHONE', 'score': np.float32(0.7718025), 'index': 23, 'word': '123-456-7890', 'start': 73, 'end': 85}]\n",
      "Text: Reach out to Jane Smith at jane.smith@domain.org or call 987-654-3210.\n",
      "Entities: [{'entity': 'EMAIL', 'score': np.float32(0.3876797), 'index': 5, 'word': 'smith', 'start': 18, 'end': 23}, {'entity': 'EMAIL', 'score': np.float32(0.83082944), 'index': 7, 'word': 'jane.smith@domain.org', 'start': 27, 'end': 48}, {'entity': 'PHONE', 'score': np.float32(0.86973166), 'index': 16, 'word': '987-654-3210', 'start': 57, 'end': 69}]\n",
      "Text: Contact Alice Johnson at alice.johnson@example.com or 555-123-4567.\n",
      "Entities: [{'entity': 'PERSON', 'score': np.float32(0.38534275), 'index': 2, 'word': 'alice', 'start': 8, 'end': 13}, {'entity': 'PERSON', 'score': np.float32(0.3453165), 'index': 3, 'word': 'johnson', 'start': 14, 'end': 21}, {'entity': 'EMAIL', 'score': np.float32(0.8273981), 'index': 5, 'word': 'alice.johnson@example.com', 'start': 25, 'end': 50}, {'entity': 'PHONE', 'score': np.float32(0.8753559), 'index': 13, 'word': '555-123-4567', 'start': 54, 'end': 66}]\n",
      "Text: Michael Brown's phone number is 800-555-0199 and email is michael.brown@domain.com.\n",
      "Entities: [{'entity': 'PERSON', 'score': np.float32(0.525183), 'index': 1, 'word': 'michael', 'start': 0, 'end': 7}, {'entity': 'EMAIL', 'score': np.float32(0.3276031), 'index': 2, 'word': 'brown', 'start': 8, 'end': 13}, {'entity': 'PHONE', 'score': np.float32(0.8738983), 'index': 8, 'word': '800-555-0199', 'start': 32, 'end': 44}, {'entity': 'PERSON', 'score': np.float32(0.33963314), 'index': 18, 'word': 'michael', 'start': 58, 'end': 65}, {'entity': 'EMAIL', 'score': np.float32(0.8287914), 'index': 19, 'word': '.brown@domain.com.', 'start': 65, 'end': 83}]\n",
      "Text: Sarah Connor works at Skynet. Her email is sarah.connor@skynet.com.\n",
      "Entities: [{'entity': 'PERSON', 'score': np.float32(0.46585986), 'index': 1, 'word': 'sarah', 'start': 0, 'end': 5}, {'entity': 'PERSON', 'score': np.float32(0.4288001), 'index': 2, 'word': 'connor', 'start': 6, 'end': 12}, {'entity': 'EMAIL', 'score': np.float32(0.8075015), 'index': 12, 'word': '.connor@', 'start': 48, 'end': 56}, {'entity': 'EMAIL', 'score': np.float32(0.74280167), 'index': 17, 'word': '.com.', 'start': 62, 'end': 67}]\n"
     ]
    }
   ],
   "source": [
    "# Post-process predictions\n",
    "def post_process_predictions(entities):\n",
    "    merged_entities = []\n",
    "    temp_entity = None\n",
    "\n",
    "    for entity in entities:\n",
    "        # Remove subword tokens (e.g., \"##\")\n",
    "        entity[\"word\"] = entity[\"word\"].replace(\"##\", \"\")\n",
    "\n",
    "        if temp_entity and entity[\"entity\"] == temp_entity[\"entity\"] and entity[\"start\"] == temp_entity[\"end\"]:\n",
    "            # Merge consecutive tokens\n",
    "            temp_entity[\"word\"] += entity[\"word\"]\n",
    "            temp_entity[\"end\"] = entity[\"end\"]\n",
    "            temp_entity[\"score\"] = max(temp_entity[\"score\"], entity[\"score\"])\n",
    "        else:\n",
    "            if temp_entity:\n",
    "                merged_entities.append(temp_entity)\n",
    "            temp_entity = entity\n",
    "\n",
    "    if temp_entity:\n",
    "        merged_entities.append(temp_entity)\n",
    "\n",
    "    # Remove duplicates and overlapping predictions\n",
    "    unique_entities = []\n",
    "    seen = set()\n",
    "    for entity in merged_entities:\n",
    "        key = (entity[\"start\"], entity[\"end\"], entity[\"entity\"])\n",
    "        if key not in seen:\n",
    "            unique_entities.append(entity)\n",
    "            seen.add(key)\n",
    "\n",
    "    return unique_entities\n",
    "\n",
    "# Test the model on additional examples\n",
    "texts = [\n",
    "    \"John Doe works at Acme Corp. His email is john.doe@acme.com and phone is 123-456-7890.\",\n",
    "    \"Reach out to Jane Smith at jane.smith@domain.org or call 987-654-3210.\",\n",
    "    \"Contact Alice Johnson at alice.johnson@example.com or 555-123-4567.\",\n",
    "    \"Michael Brown's phone number is 800-555-0199 and email is michael.brown@domain.com.\",\n",
    "    \"Sarah Connor works at Skynet. Her email is sarah.connor@skynet.com.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    entities = ner_pipeline(text)\n",
    "    cleaned_entities = post_process_predictions(entities)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Entities: {cleaned_entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13054d88",
   "metadata": {},
   "source": [
    "9. Save and Load JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "325e2584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ner_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Store results in a list\n",
    "results = []\n",
    "\n",
    "for text in texts:\n",
    "    entities = ner_pipeline(text)\n",
    "    cleaned_entities = post_process_predictions(entities)\n",
    "\n",
    "    # Convert np.float32 to float for JSON serialization\n",
    "    for entity in cleaned_entities:\n",
    "        entity[\"score\"] = float(entity[\"score\"])\n",
    "\n",
    "    results.append({\"text\": text, \"entities\": cleaned_entities})\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"ner_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"Results saved to ner_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
